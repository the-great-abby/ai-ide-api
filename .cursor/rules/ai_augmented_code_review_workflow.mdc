---
description: 
globs: 
alwaysApply: false
---
# AI-Augmented Code Review & Rule Proposal Workflow

## Overview
This rule defines the process for leveraging static analysis and LLM-powered suggestions to continuously improve code quality, enforce best practices, and integrate new rules into daily development. It is intended for both human and AI developers.

## Workflow Steps
1. **Code Authoring & Static Analysis**
   - Write or update code.
   - Run static checkers:
     ```bash
     python scripts/suggest_rules.py .
     ```
   - Review output for common issues and improvement suggestions.

2. **LLM (Ollama) Expansion (Recommended)**
   - Send static checker output and/or code snippets to the LLM for deeper analysis:
     ```bash
     python scripts/ai_rule_proposal_bot.py <suggestions.json>
     # or
     python auto_code_review.py <file_or_directory>
     ```
   - LLM generates richer rule proposals: explanations, enforcement details, examples, and documentation.

3. **Rule Proposal Submission**
   - Submit proposals to the Rule Proposal API:
     ```bash
     curl -X POST http://localhost:9103/propose-rule-change -H 'Content-Type: application/json' -d @proposal.json
     ```
   - Proposals are stored and tracked in the system.

4. **Review & Feedback Loop**
   - Team members and AI review proposals via the API or UI.
   - Provide feedback using:
     - `POST /api/rule_proposals/{proposal_id}/feedback` (accept, reject, needs_changes, comments)
   - Iterate on proposals based on feedback until consensus is reached.

5. **Rule Acceptance & Enforcement**
   - Accepted rules are versioned and stored.
   - Static checkers are updated to enforce new rules in future code reviews.
   - Changelog endpoints (`/changelog`, `/changelog.json`) keep everyone up to date.

6. **Continuous Improvement**
   - Repeat the process as code and best practices evolve.
   - Use Makefile.ai for all DB, migration, and test operations to ensure consistency.

## Best Practices
- Automate static and LLM checks as part of pre-commit hooks or CI pipelines.
- Encourage feedback from both humans and AI on all rule proposals.
- Always use Makefile.ai for environment, DB, and test management.
- Document rationale and examples for every rule/enhancement.
- Review the changelog regularly to stay current with enforced rules.
- Onboard new team members and AIs using the onboarding docs and this workflow.

## Example Daily Workflow
1. Pull latest code and rules.
2. Write or update code.
3. Run static and LLM-powered checks.
4. Submit or review rule proposals as needed.
5. Provide or review feedback.
6. Approve, reject, or iterate on proposals.
7. Ensure all tests pass using Makefile.ai targets.
8. Push changes and repeat!

## References
- [ai_augmented_code_review_workflow.md](mdc:ai_augmented_code_review_workflow.md)
- [rule_template.mdc](mdc:.cursor/rules/rule_template.mdc)
