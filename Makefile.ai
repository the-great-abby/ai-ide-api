PORT ?= 9103
ADMIN_FRONTEND_PORT ?= 3000
API_PORT ?= 9103

# TODO: Implement a script for interactive Alembic head-checking and prompting for merges.
# This will help users resolve migration graph conflicts more safely and with better UX.

# Add this near the top with other variable definitions
OLLAMA_MODEL ?= llama3.1:70b-instruct-q5_K_M

ai-up:
	docker-compose up -d api frontend

ai-down:
	docker-compose down

api-up:
	docker compose up -d api db-test

ai-test:
	docker-compose run --rm test pytest tests/ --disable-warnings --tb=short

ai-test-json:
	docker-compose run --rm test pytest --json-report --json-report-file=pytest-report.json tests/

ai-test-one:
	docker-compose run --rm test pytest $(TEST) --disable-warnings --tb=short

ai-export-rules:
	python scripts/export_approved_rules.py

ai-lint-rules:
	python scripts/lint_rules.py

ai-env:
	curl -s http://localhost:$(PORT)/env || echo '{"error": "API not running"}'

ai-status:
	docker-compose ps

ai-propose-rule:
	curl -s -X POST http://localhost:$(PORT)/propose-rule-change \
	  -H "Content-Type: application/json" \
	  -d @$(RULE_FILE)

ai-list-pending:
	curl -s http://localhost:$(PORT)/pending-rule-changes

ai-approve-rule:
	curl -s -X POST http://localhost:$(PORT)/approve-rule-change/$(PROPOSAL_ID)

ai-reject-rule:
	curl -s -X POST http://localhost:$(PORT)/reject-rule-change/$(PROPOSAL_ID)

ai-list-rules:
	curl -s http://localhost:$(PORT)/rules

ai-list-rules-mdc:
	curl -s http://localhost:$(PORT)/rules-mdc

ai-review-code-files:
	curl -s -X POST http://localhost:$(PORT)/review-code-files \
	  -F "files=@$(FILE)"

ai-review-code-snippet:
	curl -s -X POST http://localhost:$(PORT)/review-code-snippet \
	  -H "Content-Type: application/json" \
	  -d '{"filename": "$(FILENAME)", "code": "$(CODE)"}'

ai-scan-db:
	echo '--- Proposals ---'; sqlite3 rules.db 'SELECT * FROM proposals;'; \
	echo '\n--- Rules ---'; sqlite3 rules.db 'SELECT * FROM rules;'; \
	echo '\n--- Feedback ---'; sqlite3 rules.db 'SELECT * FROM feedback;' 

ai-approve-all-pending:
	python scripts/approve_all_pending.py 

ai-db-migrate:
	$(MAKE) -f Makefile.ai ai-api-wait
	docker compose exec api alembic upgrade head

ai-db-revision:
	docker compose exec api alembic revision --autogenerate -m "$(MSG)" 

ai-db-autorevision:
	docker compose exec api alembic revision --autogenerate -m "$(MSG)"

# Propose the Makefile.ai-required rule to the API (uses /propose-rule-change and $(PORT))
ai-propose-makefile-rule:
	curl -s -X POST http://localhost:$(PORT)/propose-rule-change \
	  -H "Content-Type: application/json" \
	  -d '{ \
	    "rule_type": "$(RULE_TYPE)", \
	    "description": "$(DESCRIPTION)", \
	    "diff": "$(DIFF)", \
	    "submitted_by": "$(SUBMITTED_BY)", \
	    "categories": [$(CATEGORIES)], \
	    "tags": [$(TAGS)], \
	    "project": "$(PROJECT)", \
	    "applies_to": [$(APPLIES_TO)], \
	    "applies_to_rationale": "$(APPLIES_TO_RATIONALE)", \
	    "examples": "$(EXAMPLES)", \
	    "reason_for_change": "$(REASON_FOR_CHANGE)", \
	    "references": "$(REFERENCES)", \
	    "current_rule": "$(CURRENT_RULE)" \
	  }'

# Open or fetch the FastAPI docs endpoint
ai-docs:
	curl -s http://localhost:$(PORT)/docs || echo 'Could not fetch docs. Is the API running?' 

# Show logs for all main containers (api, db-test, frontend)
logs:
	docker compose logs --tail=100 api db-test frontend || docker-compose logs --tail=100 api db-test frontend

# Show logs for just the API container
logs-api:
	docker compose logs --tail=100 api || docker-compose logs --tail=100 api

# Show logs for just the database container
logs-db:
	docker compose logs --tail=100 db-test || docker-compose logs --tail=100 db-test

# Open the FastAPI docs in the default browser (macOS)
open-docs:
	open http://localhost:$(PORT)/docs 

open-admin:
	open http://localhost:$(ADMIN_FRONTEND_PORT)

ai-build:
	docker-compose build 

ai-rebuild-all:
	docker-compose down
	docker system prune -af
	docker-compose build 

ai-import-backup:
	docker compose exec api python import_from_backup.py

ai-bug-report:
	curl -s -X POST http://localhost:$(PORT)/bug-report \
	  -H 'Content-Type: application/json' \
	  -d '{"description": "$(DESCRIPTION)", "reporter": "$(REPORTER)", "page": "$(PAGE)"}'

ai-bug-report-test:
	$(MAKE) -f Makefile.ai ai-bug-report \
	  DESCRIPTION='Test bug report from Makefile' \
	  REPORTER='cli-test' \
	  PAGE='/admin'

ai-suggest-enhancement:
	curl -s -X POST http://localhost:$(PORT)/suggest-enhancement \
	  -H 'Content-Type: application/json' \
	  -d '{"description": "$(DESCRIPTION)", "suggested_by": "$(SUGGESTED_BY)", "page": "$(PAGE)", "tags": [$(TAGS)], "categories": [$(CATEGORIES)]}'

ai-suggest-enhancement-test:
	$(MAKE) -f Makefile.ai ai-suggest-enhancement \
	  DESCRIPTION='Test enhancement from Makefile' \
	  SUGGESTED_BY='cli-test' \
	  PAGE='/admin' \
	  TAGS='"cli","test"' \
	  CATEGORIES='"usability"'

ai-enhancement-to-proposal:
	curl -s -X POST http://localhost:$(PORT)/enhancement-to-proposal/$(ENHANCEMENT_ID)

ai-proposal-to-enhancement:
	curl -s -X POST http://localhost:$(PORT)/proposal-to-enhancement/$(PROPOSAL_ID)

ai-accept-enhancement:
	curl -s -X POST http://localhost:$(PORT)/accept-enhancement/$(ENHANCEMENT_ID)

ai-complete-enhancement:
	curl -s -X POST http://localhost:$(PORT)/complete-enhancement/$(ENHANCEMENT_ID)

ai-list-enhancements:
	@if [ -z "$(STATUS)" ]; then \
	  curl -s http://localhost:$(PORT)/enhancements | jq '.'; \
	else \
	  curl -s http://localhost:$(PORT)/enhancements | jq '.[] | select(.status == "$(STATUS)")'; \
	fi

ai-onboarding-health:
	python scripts/onboarding_health_check.py

# Migrate rules.db (SQLite) to Postgres using pgloader in Docker
# Usage: make -f Makefile.ai ai-migrate-sqlite-to-postgres
ai-migrate-sqlite-to-postgres:
	docker-compose up -d rules-postgres pgloader
	docker cp rules.db pgloader:/data/rules.db
	docker cp pgloader.load pgloader:/data/pgloader.load
	docker-compose exec pgloader pgloader /data/pgloader.load
	@echo "Migration from SQLite to Postgres complete!"

# Build the custom pgloader image for multi-arch (Apple Silicon) compatibility
# Usage: make -f Makefile.ai ai-build-pgloader
ai-build-pgloader:
	docker build -f Dockerfile.pgloader -t local/pgloader:latest .

# Migrate all tables from rules.db (SQLite) to Postgres using CSV and psql in Docker
# Usage: make -f Makefile.ai ai-migrate-sqlite-to-postgres-csv
ai-migrate-sqlite-to-postgres-csv:
	mkdir -p sqlite_export
	docker run --rm -v $(PWD):/data alpine:latest sh -c 'apk add --no-cache sqlite sqlite-libs > /dev/null && sqlite3 /data/rules.db ".tables" | tr " " "\n" | grep -v "^$$" | while read tbl; do sqlite3 /data/rules.db ".headers on" ".mode csv" ".output /data/sqlite_export/$$tbl.csv" "select * from \"$$tbl\";" ".output stdout"; done'
	docker run --rm -v $(PWD):/data alpine:latest sh -c 'apk add --no-cache sqlite sqlite-libs > /dev/null && sqlite3 /data/rules.db ".schema" > /data/sqlite_export/schema.sql'
	# Patch schema.sql: replace DATETIME with TIMESTAMPTZ and add DROP TABLE IF EXISTS
	sed -i '' 's/DATETIME/TIMESTAMPTZ/g' sqlite_export/schema.sql
	awk '/^CREATE TABLE /{print "DROP TABLE IF EXISTS " $$3 " CASCADE;"} 1' sqlite_export/schema.sql > sqlite_export/schema.patched.sql
	chmod +x import_csvs.sh
	docker run --rm -e PGPASSWORD=postgres -v $(PWD):/data --network ai-ide-api_default postgres:15 bash /data/import_csvs.sh
	@echo "Migration from SQLite to Postgres via CSV complete!"

# Propose a portable rule to the API
# Usage:
# make -f Makefile.ai ai-propose-portable-rule \
#   RULE_TYPE=formatting \
#   DESCRIPTION='All .mdc files must have frontmatter' \
#   DIFF='---\ndescription: ...\nglobs: ...\n---' \
#   SUBMITTED_BY=portable-rules-bot \
#   CATEGORIES='"formatting","cursor","portable"' \
#   TAGS='"formatting","cursor","portable"' \
#   PROJECT=my-shared-rules \
#   [API_PORT=9103]
ai-propose-portable-rule:
	curl -s -X POST http://localhost:$(API_PORT)/propose-rule-change \
	  -H 'Content-Type: application/json' \
	  -d '{ \
	    "rule_type": "$(RULE_TYPE)", \
	    "description": "$(DESCRIPTION)", \
	    "diff": "$(DIFF)", \
	    "submitted_by": "$(SUBMITTED_BY)", \
	    "categories": [$(CATEGORIES)], \
	    "tags": [$(TAGS)], \
	    "project": "$(PROJECT)", \
	    "reason_for_change": "$(REASON_FOR_CHANGE)", \
	    "references": "$(REFERENCES)", \
	    "current_rule": "$(CURRENT_RULE)" \
	  }'

# Rollback any failed transaction in the Postgres database (useful for clearing migration errors)
# Usage: make -f Makefile.ai ai-db-rollback
ai-db-rollback:
	docker compose exec -T db-test psql -U postgres -d rulesdb -c 'ROLLBACK;'

# Reset the database migration state (for development):
# 1. Stops all containers
# 2. Restarts only the db-test container
# 3. Runs ai-db-rollback to clear failed transactions
# 4. Restarts all containers
# 5. Runs ai-db-migrate to apply migrations
# Usage: make -f Makefile.ai ai-db-reset-migrations
ai-db-reset-migrations:
	docker compose down
	docker compose up -d db-test
	$(MAKE) -f Makefile.ai ai-db-rollback
	docker compose up -d
	$(MAKE) -f Makefile.ai ai-db-migrate

# Backup the rulesdb database to backups/rulesdb-YYYYMMDD-HHMMSS.sql
# Usage: make -f Makefile.ai ai-db-backup
ai-db-backup:
	mkdir -p backups
	docker compose exec -T db-test pg_dump -U postgres -d rulesdb > backups/rulesdb-`date +"%Y%m%d-%H%M%S"`.sql

# Drop and recreate the rulesdb database, then run migrations (development only!)
# Usage: make -f Makefile.ai ai-db-drop-recreate
ai-db-drop-recreate:
	docker compose exec -T db-test psql -U postgres -c 'DROP DATABASE IF EXISTS rulesdb;'
	docker compose exec -T db-test psql -U postgres -c 'CREATE DATABASE rulesdb;'
	$(MAKE) -f Makefile.ai ai-db-migrate

# Drop the statusenum type from Postgres (if it exists)
# Usage: make -f Makefile.ai ai-db-drop-statusenum
ai-db-drop-statusenum:
	docker compose cp scripts/drop_statusenum.sql db-test:/tmp/drop_statusenum.sql
	docker compose exec -T db-test psql -U postgres -d rulesdb -f /tmp/drop_statusenum.sql

# Danger: This will delete ALL Postgres data and volumes!
# Usage: make -f Makefile.ai ai-db-nuke
ai-db-nuke:
	docker compose down -v
	docker compose up -d db-test

# Restore the rulesdb database from a SQL backup file
# Usage: make -f Makefile.ai ai-db-restore BACKUP=backups/rulesdb-YYYYMMDD-HHMMSS.sql
ai-db-restore:
	docker compose exec -T db-test psql -U postgres -d rulesdb < $(BACKUP)

# Restore only the data (not schema) from a SQL backup file
# Usage: make -f Makefile.ai ai-db-restore-data BACKUP=backups/rulesdb-YYYYMMDD-HHMMSS.sql
ai-db-restore-data:
	cat $(BACKUP) | grep -vE '^CREATE |^ALTER |^DROP |^--' | docker compose exec -T db-test psql -U postgres -d rulesdb

# Backup only the data (no schema) from the rulesdb database
# Usage: make -f Makefile.ai ai-db-backup-data-only
ai-db-backup-data-only:
	mkdir -p backups
	docker compose exec -T db-test pg_dump --data-only -U postgres -d rulesdb > backups/rulesdb-data-`date +"%Y%m%d-%H%M%S"`.sql

# Merge Alembic heads automatically (use with caution!)
ai-db-merge-heads:
	docker compose exec api alembic heads

ai-db-heads:
	docker compose exec api alembic heads

ai-db-history:
	docker compose exec api alembic history --verbose

ai-api-wait:
	@echo "Waiting for API to be ready..."
	@until curl -sf http://localhost:$(API_PORT)/env > /dev/null; do sleep 2; done
	@echo "API is up!"

ai-db-nuke-and-restore-data:
	$(MAKE) -f Makefile.ai ai-db-backup-data-only
	$(MAKE) -f Makefile.ai ai-db-nuke
	$(MAKE) -f Makefile.ai ai-up
	$(MAKE) -f Makefile.ai ai-api-wait
	$(MAKE) -f Makefile.ai ai-db-migrate
	BACKUP=$$(ls -t backups/rulesdb-data-*.sql | head -1) $(MAKE) -f Makefile.ai ai-db-restore-data

ai-misc-install:
	docker compose exec misc-scripts pip install -r requirements.txt

ai-misc-up:
	docker compose up -d misc-scripts

ai-misc-update-rules:
	$(MAKE) -f Makefile.ai ai-misc-up
	docker compose exec misc-scripts pip install -r requirements.txt
	docker compose exec misc-scripts python update_rules.py

ai-misc-generate-update-template:
	docker compose exec misc-scripts python generate_rules_update_template.py

ai-api-restart-wait:
	docker compose restart api
	$(MAKE) -f Makefile.ai ai-api-wait

ai-propose-rules:
	bash misc_scripts/propose_rules.sh

ai-misc-mdc-to-json: ai-misc-install
	docker compose exec misc-scripts python mdc_to_json_rule_proposals.py

ai-misc-enrich-rules:
	docker compose exec misc-scripts python enrich_rule_proposals.py

ai-list-bug-reports:
	curl -s http://localhost:$(PORT)/bug-reports | jq '.'

ai-db-stamp-head:
	docker compose exec api alembic stamp head

schema-proposals:
	docker compose exec db-test psql -U postgres -d rulesdb -c '\d+ proposals' | cat

docker-pre-commit:
	docker run --rm -v $(PWD):/code -w /code local/pre-commit:latest run --all-files

docker-build-pre-commit:
	docker build -f Dockerfile.pre-commit -t local/pre-commit:latest .

ai-review-multiple-files:
	python scripts/review_multiple_files.py $(FILES)

ai-suggest-llm-rules:
	OLLAMA_URL=$(OLLAMA_URL) RULE_API_URL=$(RULE_API_URL) \
	python scripts/suggest_and_propose_rules.py $${TARGET-.}

# Run the LLM-powered rule suggestion pipeline inside Docker
# Usage: make -f Makefile.ai ai-suggest-llm-rules-docker TARGET=your/dir/or/file
ai-suggest-llm-rules-docker:
	docker compose run --rm \
	  -e RUNNING_IN_DOCKER=1 \
	  -e OLLAMA_URL=$(OLLAMA_URL) -e RULE_API_URL=$(RULE_API_URL) \
	  ollama-functions python scripts/suggest_and_propose_rules.py $${TARGET-.}

# Build and run the LLM rule suggester FastAPI service
# Usage:
#   make -f Makefile.ai ai-build-ollama-functions-service
#   make -f Makefile.ai ai-run-ollama-functions-service
OLLAMA_FUNCTIONS_IMAGE ?= ollama-functions:latest

# Default Ollama URL for LLM rule suggester service (can be overridden)
OLLAMA_URL ?= http://host.docker.internal:11434/api/generate

ai-build-ollama-functions-service:
	docker build -f Dockerfile.ollama_functions -t $(OLLAMA_FUNCTIONS_IMAGE) .

ai-run-ollama-functions-service: ai-build-ollama-functions-service
	docker run --rm -e RUNNING_IN_DOCKER=1 \
	  --add-host=host.docker.internal:host-gateway \
	  -e OLLAMA_URL=$(OLLAMA_URL) \
	  -e OLLAMA_MODEL=$(OLLAMA_MODEL) \
	  -v $(PWD):/code -w /code \
	  -p 8000:8000 \
	  $(OLLAMA_FUNCTIONS_IMAGE)

# Find the Docker bridge gateway IP
ai-docker-gateway-ip:
	@docker network inspect bridge | grep Gateway | head -1 | awk -F '"' '{print $$4}'

# Start Ollama on the Docker gateway IP
# Usage: make -f Makefile.ai ai-ollama-serve-docker-gateway
# (You may want to run this in a separate terminal)
ai-ollama-serve-docker-gateway:
	@echo "Starting Ollama on 0.0.0.0:11434..."
	OLLAMA_HOST=0.0.0.0 ollama serve

# Note: If you use the gateway IP, set OLLAMA_URL to http://<gateway-ip>:11434/api/generate for ai-run-ollama-functions-service

# Kill all running Ollama processes
ai-ollama-kill:
	pkill -f 'ollama serve' || true

# Restart Ollama on the Docker gateway IP
# Usage: make -f Makefile.ai ai-ollama-restart-docker-gateway
ai-ollama-restart-docker-gateway: ai-ollama-kill
	$(MAKE) -f Makefile.ai ai-ollama-serve-docker-gateway

# Note: The following targets run Ollama in the foreground. For automation, run in the background:
#   make -f Makefile.ai ai-ollama-serve-docker-gateway &
# or
#   nohup make -f Makefile.ai ai-ollama-serve-docker-gateway > ollama.log 2>&1 &
# Or use the provided background target:
#   make -f Makefile.ai ai-ollama-serve-docker-gateway-bg

ai-ollama-serve-docker-gateway-bg:
	nohup $(MAKE) -f Makefile.ai ai-ollama-serve-docker-gateway > ollama.log 2>&1 &

# View the last 100 lines of the Ollama log file from the background run
# Usage: make -f Makefile.ai ai-ollama-logs
ai-ollama-logs:
	tail -n 100 ollama.log

ai-admin-frontend-nocache-restart:
	docker compose build --no-cache frontend
	docker compose restart frontend

# Download a model for Ollama (default: $(OLLAMA_MODEL))
# Usage: make -f Makefile.ai ai-ollama-pull-model [OLLAMA_MODEL=modelname]
ai-ollama-pull-model:
	ollama pull $(OLLAMA_MODEL)

# Onboarding: One-command setup for LLM/Ollama integration
ai-llm-setup:
	@echo "[LLM Setup] Downloading Ollama model if not present..."
	$(MAKE) -f Makefile.ai ai-ollama-pull-model
	@echo "[LLM Setup] Starting Ollama service (docker gateway)..."
	$(MAKE) -f Makefile.ai ai-ollama-serve-docker-gateway &
	@echo "[LLM Setup] Waiting for Ollama service to be ready..."
	@sleep 5
	@echo "[LLM Setup] Verifying Ollama service is running..."
	@if curl -sf http://localhost:11434 | grep -q 'Ollama'; then \
		echo '[LLM Setup] Ollama service is running!'; \
		echo '[LLM Setup] You can now use LLM-powered features.'; \
	else \
		echo '[LLM Setup] ERROR: Ollama service did not start. Please check logs with: make -f Makefile.ai ai-ollama-logs'; \
		exit 1; \
	fi